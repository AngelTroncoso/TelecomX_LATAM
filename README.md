 #                                                    Proyecto: PredicciÃ³n de CancelaciÃ³n de Servicios

![AnÃ¡lisis de datos](https://image.lexica.art/full_webp/7b3d9d65-32a9-4468-bded-d1c2926f77da)

# ğŸ§  DescripciÃ³n

Este proyecto utiliza Machine Learning para predecir la probabilidad de que un cliente cancele su servicio. Se emplean modelos de **Random Forest** y **XGBoost** para analizar mÃºltiples variables demogrÃ¡ficas y de comportamiento.

- **ETL (Extract, Transform, Load):** Limpieza y preparaciÃ³n de datos desde mÃºltiples fuentes.
- **EDA (Exploratory Data Analysis):** AnÃ¡lisis exploratorio para entender patrones y relaciones en los datos.
- **Machine Learning:** Modelos predictivos (Random Forest, XGBoost) para predecir la probabilidad de cancelaciÃ³n y ayudar a la toma de decisiones.

---

# ğŸ› ï¸ Variables principales

- `Cancelado` (variable objetivo)
- `Tiene_dependientes`
- `ProtecciÃ³n_dispositivos`
- `Servicio_telefonÃ­a`
- `Tiene_pareja`
- `Factura_sin_papel`
- `Cargo_mensual`
- `AntigÃ¼edad_meses`
- ...y otras variables relevantes de comportamiento y facturaciÃ³n.

---

# ğŸ“‚ Estructura del proyecto

- `data/` - Datos de entrada.
- `notebooks/` - AnÃ¡lisis exploratorio, entrenamiento y evaluaciÃ³n.
- `models/` - Modelos entrenados.
- `scripts/` - CÃ³digo de procesamiento y modelado.
- `README.md` - Este archivo.

---

# ğŸ”‘ Requisitos

Python 3.8+ con librerÃ­as:

```bash
pip install pandas scikit-learn xgboost matplotlib seaborn
```
---

# ğŸš€ Uso del Proyecto
Cargar y limpiar los datos.

Entrenar los modelos Random Forest y XGBoost.

Evaluar resultados con mÃ©tricas como accuracy, precision, recall, f1-score y ROC AUC.

Visualizar la importancia de variables con grÃ¡ficos.

---
# ğŸ“Š Resultados Obtenidos

Random Forest alcanzÃ³ un accuracy aproximado del 56% y un f1-score balanceado.

XGBoost mostrÃ³ mÃ©tricas similares con un ROC AUC cercano a 0.52.

Variables como Cargo_mensual, AntigÃ¼edad_meses y Tiene_dependientes son clave para la predicciÃ³n.
---
# ğŸ“ˆ Mejoras Futuras

âš™ï¸OptimizaciÃ³n de hiperparÃ¡metros con tÃ©cnicas avanzadas.

ğŸ§ª Experimentar con otros modelos (SVM, Redes Neuronales).

ğŸ”„ Implementar pipelines para automatizar el flujo completo.

---
# ğŸ“„ Licencia  

  Este proyecto estÃ¡ bajo la Licencia MIT. Puedes consultar el archivo LICENSE para mÃ¡s detalles.

---

# ğŸ¤ Contribuciones
Â¡Tu contribuciÃ³n es muy bienvenida! Si te gustarÃ­a mejorar este proyecto, puedes:

- Forkear el repositorio.
- Crear una nueva rama (git checkout -b feature/AmazingFeature).
- Realizar tus cambios y commitarlos (git commit -m 'Add some AmazingFeature').

- Hacer push a la rama (git push origin feature/AmazingFeature).
- Abrir un Pull Request.

  **Â¡Agradecemos de antemano tu colaboraciÃ³n!**
  
---

# âœ‰ï¸ Contacto
Â¡No dudes en contactarme para cualquier pregunta o colaboraciÃ³n!

ğŸ“§ [Correo](mailto:angeltroncoso2019@outlook.es)  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/angeltroncoso)  
ğŸ¦ [Twitter](https://twitter.com/angeltronc26452)  
ğŸ’¼ [GitHub](https://github.com/angeltroncoso)  

---
